{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\My book\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n",
      "   age          job  marital  education default  balance housing loan  \\\n",
      "0   30   unemployed  married    primary      no     1787      no   no   \n",
      "1   33     services  married  secondary      no     4789     yes  yes   \n",
      "2   35   management   single   tertiary      no     1350     yes   no   \n",
      "3   30   management  married   tertiary      no     1476     yes  yes   \n",
      "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
      "\n",
      "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
      "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
      "1  cellular   11   may       220         1    339         4  failure  no  \n",
      "2  cellular   16   apr       185         1    330         1  failure  no  \n",
      "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
      "4   unknown    5   may       226         1     -1         0  unknown  no  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        4521 non-null   int64 \n",
      " 1   job        4521 non-null   object\n",
      " 2   marital    4521 non-null   object\n",
      " 3   education  4521 non-null   object\n",
      " 4   default    4521 non-null   object\n",
      " 5   balance    4521 non-null   int64 \n",
      " 6   housing    4521 non-null   object\n",
      " 7   loan       4521 non-null   object\n",
      " 8   contact    4521 non-null   object\n",
      " 9   day        4521 non-null   int64 \n",
      " 10  month      4521 non-null   object\n",
      " 11  duration   4521 non-null   int64 \n",
      " 12  campaign   4521 non-null   int64 \n",
      " 13  pdays      4521 non-null   int64 \n",
      " 14  previous   4521 non-null   int64 \n",
      " 15  poutcome   4521 non-null   object\n",
      " 16  y          4521 non-null   object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 600.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Load the dataset\n",
    "# Replace 'path_to_your_file/bank.csv' with your actual file path after downloading\n",
    "data = pd.read_csv(\"bank.csv\", delimiter=';')\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", data.isnull().sum())\n",
    "\n",
    "# Basic data exploration\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    if column != 'y':  # Target variable encoding done separately\n",
    "        le = LabelEncoder()\n",
    "        data[column] = le.fit_transform(data[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode the target variable 'y' (1 for 'yes', 0 for 'no')\n",
    "data['y'] = data['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,713\n",
      "Trainable params: 3,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3376 - accuracy: 0.8811 - val_loss: 0.2756 - val_accuracy: 0.8957\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2738 - accuracy: 0.8894 - val_loss: 0.2667 - val_accuracy: 0.8894\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2571 - accuracy: 0.8933 - val_loss: 0.2660 - val_accuracy: 0.8926\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.8973 - val_loss: 0.2636 - val_accuracy: 0.8878\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 0.8985 - val_loss: 0.2637 - val_accuracy: 0.8878\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.8969 - val_loss: 0.2642 - val_accuracy: 0.8863\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9028 - val_loss: 0.2608 - val_accuracy: 0.8926\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.9064 - val_loss: 0.2635 - val_accuracy: 0.8926\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9091 - val_loss: 0.2713 - val_accuracy: 0.8926\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2151 - accuracy: 0.9131 - val_loss: 0.2694 - val_accuracy: 0.8894\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9119 - val_loss: 0.2688 - val_accuracy: 0.8942\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9190 - val_loss: 0.2712 - val_accuracy: 0.8989\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9210 - val_loss: 0.2789 - val_accuracy: 0.8957\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1922 - accuracy: 0.9206 - val_loss: 0.2752 - val_accuracy: 0.8973\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.9241 - val_loss: 0.2772 - val_accuracy: 0.9021\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.9261 - val_loss: 0.2927 - val_accuracy: 0.8894\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9273 - val_loss: 0.2985 - val_accuracy: 0.8910\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9356 - val_loss: 0.3045 - val_accuracy: 0.8768\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1642 - accuracy: 0.9364 - val_loss: 0.3074 - val_accuracy: 0.8815\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1585 - accuracy: 0.9384 - val_loss: 0.3150 - val_accuracy: 0.8894\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1524 - accuracy: 0.9364 - val_loss: 0.3203 - val_accuracy: 0.8847\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9427 - val_loss: 0.3259 - val_accuracy: 0.8847\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1418 - accuracy: 0.9459 - val_loss: 0.3272 - val_accuracy: 0.8815\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1374 - accuracy: 0.9431 - val_loss: 0.3393 - val_accuracy: 0.8799\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1296 - accuracy: 0.9494 - val_loss: 0.3573 - val_accuracy: 0.8863\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1262 - accuracy: 0.9478 - val_loss: 0.3640 - val_accuracy: 0.8799\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9561 - val_loss: 0.3622 - val_accuracy: 0.8831\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.9577 - val_loss: 0.3741 - val_accuracy: 0.8784\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1089 - accuracy: 0.9609 - val_loss: 0.3909 - val_accuracy: 0.8752\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1098 - accuracy: 0.9601 - val_loss: 0.4130 - val_accuracy: 0.8847\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9625 - val_loss: 0.4235 - val_accuracy: 0.8705\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9621 - val_loss: 0.4341 - val_accuracy: 0.8752\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9723 - val_loss: 0.4314 - val_accuracy: 0.8894\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9696 - val_loss: 0.4523 - val_accuracy: 0.8815\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.0804 - accuracy: 0.9751 - val_loss: 0.4875 - val_accuracy: 0.8784\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9755 - val_loss: 0.4954 - val_accuracy: 0.8784\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.4894 - val_accuracy: 0.8752\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 0.4996 - val_accuracy: 0.8768\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9802 - val_loss: 0.5277 - val_accuracy: 0.8689\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9818 - val_loss: 0.5502 - val_accuracy: 0.8784\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9846 - val_loss: 0.5843 - val_accuracy: 0.8689\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9866 - val_loss: 0.5994 - val_accuracy: 0.8720\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0560 - accuracy: 0.9838 - val_loss: 0.6299 - val_accuracy: 0.8752\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9862 - val_loss: 0.6460 - val_accuracy: 0.8689\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9866 - val_loss: 0.6586 - val_accuracy: 0.8736\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9854 - val_loss: 0.6812 - val_accuracy: 0.8705\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9881 - val_loss: 0.6970 - val_accuracy: 0.8705\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9881 - val_loss: 0.7149 - val_accuracy: 0.8689\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0409 - accuracy: 0.9897 - val_loss: 0.7051 - val_accuracy: 0.8641\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9897 - val_loss: 0.7404 - val_accuracy: 0.8562\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.8622\n",
      "Test Loss: 0.6410366892814636\n",
      "Test Accuracy: 0.8621960282325745\n"
     ]
    }
   ],
   "source": [
    "# Define the ANN model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # 64 neurons, ReLU activation\n",
    "\n",
    "# Add more hidden layers as needed\n",
    "model.add(Dense(32, activation='relu'))  # Second hidden layer with 32 neurons\n",
    "model.add(Dense(16, activation='relu'))  # Third hidden layer with 16 neurons\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
